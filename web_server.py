import asyncio
import json
import os
from typing import Any, Dict, List, Optional
import httpx
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from fastmcp import Client as MCPClient
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

app = FastAPI(title="AI Agent Web Server", version="1.0.0")

# CORS ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œ ì—°ê²°ì„ ìœ„í•´)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # í”„ë¡ íŠ¸ì—”ë“œ ì£¼ì†Œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
SERVER_PATH = os.getenv("MCP_SERVER_PATH", "server.py")
BACKEND_BASE_URL = os.getenv("BACKEND_BASE_URL", "http://localhost:8080")

# ê¸€ë¡œë²Œ ë³€ìˆ˜ë“¤
mcp_client: Optional[MCPClient] = None
openai_client: OpenAI = OpenAI()
openai_tools: List[Dict[str, Any]] = []


# ìš”ì²­/ì‘ë‹µ ëª¨ë¸
class ChatRequest(BaseModel):
    message: str
    user_id: Optional[str] = None
    cookies: Optional[str] = None


class ChatResponse(BaseModel):
    response: str
    status: str = "success"


class NotionPageData(BaseModel):
    notionPageId: str
    notionPageText: str


# ---------- ìœ í‹¸ í•¨ìˆ˜ë“¤ (client.pyì—ì„œ ê°€ì ¸ì˜´) ----------
def _to_dict(x: Any):
    """Pydantic(BaseModel) -> dict, ê·¸ ì™¸ëŠ” ê·¸ëŒ€ë¡œ"""
    if hasattr(x, "model_dump"):
        return x.model_dump()
    if hasattr(x, "dict"):
        return x.dict()
    return x


# U+D800..U+DFFF ì œê±°ìš© ë§¤í•‘ (ìœ íš¨í•˜ì§€ ì•Šì€ ì„œëŸ¬ê²Œì´íŠ¸ ë²”ìœ„)
_SURR_MAP = {i: None for i in range(0xD800, 0xE000)}


def _strip_surrogates(s: str) -> str:
    """ë¬¸ìì—´ì—ì„œ ì„œëŸ¬ê²Œì´íŠ¸ ì½”ë“œí¬ì¸íŠ¸ ì œê±°"""
    return s.translate(_SURR_MAP)


def _sanitize(obj: Any):
    """ë¬¸ìì—´/ë¦¬ìŠ¤íŠ¸/ë”•ì…”ë„ˆë¦¬(ë˜ëŠ” Pydantic)ë¥¼ ì¬ê·€ì ìœ¼ë¡œ ì •ë¦¬"""
    if isinstance(obj, str):
        return _strip_surrogates(obj)
    if isinstance(obj, list):
        return [_sanitize(v) for v in obj]
    if isinstance(obj, dict):
        return {(_sanitize(k) if isinstance(k, str) else k): _sanitize(v) for k, v in obj.items()}
    if hasattr(obj, "model_dump"):
        return _sanitize(obj.model_dump())
    if hasattr(obj, "dict"):
        return _sanitize(obj.dict())
    return obj


def _mcp_schema_to_openai_tool(tool: Any) -> Dict[str, Any]:
    """FastMCPì˜ Tool(Pydantic) ë˜ëŠ” dictë¥¼ OpenAI tools ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜."""
    t = _to_dict(tool)  # Pydantic -> dict
    name = t.get("name") or t.get("tool") or "tool"
    description = t.get("description", "")
    schema = t.get("inputSchema") or t.get("input_schema") or {"type": "object", "properties": {}}

    return {
        "type": "function",
        "function": {
            "name": _strip_surrogates(name),
            "description": _strip_surrogates(description),
            "parameters": _sanitize(schema),
        },
    }


def _to_str(res: Any) -> str:
    """íˆ´ ì‹¤í–‰ ê²°ê³¼ë¥¼ OpenAI tool ë©”ì‹œì§€ contentë¡œ ì•ˆì „ ë³€í™˜"""
    if isinstance(res, str):
        return _strip_surrogates(res)
    if hasattr(res, "text") and isinstance(res.text, str):
        return _strip_surrogates(res.text)
    d = _to_dict(res)
    try:
        return _strip_surrogates(json.dumps(_sanitize(d), ensure_ascii=False))
    except Exception:
        return _strip_surrogates(str(d))


# ---------- ë°±ì—”ë“œ API ì—°ë™ í•¨ìˆ˜ë“¤ ----------
async def get_user_info(user_id: str) -> Dict[str, Any]:
    """ë°±ì—”ë“œì—ì„œ ì‚¬ìš©ì ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    async with httpx.AsyncClient() as client:
        response = await client.get(f"{BACKEND_BASE_URL}/api/users/{user_id}")
        if response.status_code == 200:
            return response.json()
        else:
            raise HTTPException(status_code=response.status_code, detail="Failed to get user info")


async def save_notion_page_to_backend(user_id: str, notion_data: NotionPageData) -> Dict[str, Any]:
    """ë°±ì—”ë“œì— ë…¸ì…˜ í˜ì´ì§€ ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
    async with httpx.AsyncClient() as client:
        response = await client.post(
            f"{BACKEND_BASE_URL}/api/users/{user_id}/notion",
            json=notion_data.model_dump()
        )
        if response.status_code in [200, 201]:
            return response.json()
        else:
            raise HTTPException(status_code=response.status_code, detail="Failed to save notion data")


# ---------- AI ì—ì´ì „íŠ¸ ì²˜ë¦¬ í•¨ìˆ˜ ----------
async def process_chat_with_ai(message: str, user_id: Optional[str] = None, cookies: Optional[str] = None) -> str:
    """AI ì—ì´ì „íŠ¸ì™€ ì±„íŒ…ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    global mcp_client, openai_tools
    
    if not mcp_client:
        raise HTTPException(status_code=500, detail="MCP client not initialized")

    # ì¿ í‚¤ ì •ë³´ë¥¼ í•¨ìˆ˜ ì „ì²´ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì €ì¥
    final_cookies = cookies or ""

    messages: List[Dict[str, Any]] = [
        {
            "role": "system",
            "content": (
                "You are a helpful assistant with access to Notion tools and backend API. "
                "When user asks about their Notion content, use the available tools to search and retrieve information. "
                "If the user asks to update or save Notion data, you should also call the backend API. "
                "Always respond in Korean. "
                f"Current user ID: {user_id if user_id else 'Not provided'}"
            ),
        },
        {"role": "user", "content": _strip_surrogates(message)}
    ]

    # ì‚¬ìš©ì IDê°€ ìˆëŠ” ê²½ìš° ì‚¬ìš©ìë³„ ë…¸ì…˜ ë„êµ¬ ì‚¬ìš©ì„ ê¶Œì¥
    if user_id:
        auth_instruction = f"user_id=\"{user_id}\""
        if final_cookies:
            auth_instruction += f", cookies=\"{final_cookies}\""
            
        messages[0]["content"] += (
            f"\nIMPORTANT AUTHENTICATION RULES:\n"
            f"- User ID: {user_id}\n"
            f"- MANDATORY: When calling ANY user-specific tool, you MUST include these exact parameters: {auth_instruction}\n"
            f"- ALWAYS use 'notion_search_with_user' and 'notion_page_content_with_user' (never the basic versions)\n"
            f"- ALWAYS use 'get_user_info' with cookies before any Notion operations\n"
            f"- The backend API returns lowercase fields: 'access_token', 'refresh_token', etc.\n"
            f"- Example tool call: notion_search_with_user({auth_instruction}, query=\"search term\")\n"
            f"- If you get an access_token from backend, the user HAS authorized Notion access.\n"
            f"- NOTE: Authentication parameters will be automatically added to tool calls if missing.\n"
        )

    # Tool-call ë£¨í”„
    max_iterations = 10  # ë¬´í•œ ë£¨í”„ ë°©ì§€
    iteration = 0
    
    while iteration < max_iterations:
        iteration += 1
        
        resp = openai_client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=_sanitize(messages),
            tools=openai_tools,
        )
        choice = resp.choices[0]
        msg = choice.message

        if msg.tool_calls:
            # íˆ´ í˜¸ì¶œ ì²˜ë¦¬
            tool_results = []
            for tc in msg.tool_calls:
                tname = tc.function.name
                targs = tc.function.arguments or "{}"
                try:
                    parsed = json.loads(targs)
                except json.JSONDecodeError:
                    parsed = {}

                # MCP íˆ´ ì‹¤í–‰ - ì‚¬ìš©ìë³„ ë„êµ¬ì¸ ê²½ìš° ì¸ì¦ ì •ë³´ ìë™ ì¶”ê°€
                if user_id and tname in ['get_user_info', 'notion_search_with_user', 'notion_page_content_with_user']:
                    # ì¸ì¦ ì •ë³´ê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ì¶”ê°€
                    if 'user_id' not in parsed:
                        parsed['user_id'] = user_id
                    if final_cookies and 'cookies' not in parsed:
                        parsed['cookies'] = final_cookies
                    
                    print(f"ğŸ”§ Auto-added auth to {tname}: user_id={user_id}, has_cookies={bool(final_cookies)}")
                
                result = await mcp_client.call_tool(tname, parsed)
                tool_results.append((tc, tname, parsed, result))

            # ëª¨ë¸ì˜ íˆ´ í˜¸ì¶œ ë©”ì‹œì§€ ì¶”ê°€
            messages.append(
                {
                    "role": "assistant",
                    "tool_calls": [
                        {
                            "id": tc.id,
                            "type": "function",
                            "function": {"name": tname, "arguments": json.dumps(parsed, ensure_ascii=False)},
                        }
                        for tc, tname, parsed, _ in tool_results
                    ],
                }
            )
            
            # íˆ´ ê²°ê³¼ ë©”ì‹œì§€ë“¤ ì¶”ê°€
            for tc, tname, parsed, result in tool_results:
                messages.append(
                    {
                        "role": "tool",
                        "tool_call_id": tc.id,
                        "name": tname,
                        "content": _to_str(result),
                    }
                )

            # ë…¸ì…˜ í˜ì´ì§€ ì»¨í…ì¸ ë¥¼ ê°€ì ¸ì˜¨ ê²½ìš° - MCP ë„êµ¬ì—ì„œ ìë™ìœ¼ë¡œ ë°±ì—”ë“œ ì €ì¥ ì²˜ë¦¬
            # (save_notion_data_to_backend MCP ë„êµ¬ê°€ ì´ë¥¼ ì²˜ë¦¬í•¨)

            # íˆ´ ì¶œë ¥ê¹Œì§€ ëŒ€í™”ì— ë°˜ì˜í–ˆìœ¼ë‹ˆ, í•œ ë²ˆ ë” ìš”ì²­í•´ ìµœì¢… ë‹µë³€ ë°›ê¸°
            continue

        # ë” ì´ìƒ íˆ´ í˜¸ì¶œì´ ì—†ìœ¼ë©´ ìµœì¢… ë‹µë³€
        final_text = msg.content or ""
        return _strip_surrogates(final_text)

    return "ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."


# ---------- ì‹œì‘/ì¢…ë£Œ ì´ë²¤íŠ¸ ----------
@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ MCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
    global mcp_client, openai_tools
    
    try:
        # MCP í´ë¼ì´ì–¸íŠ¸ ìƒì„± (stdio ë°©ì‹)
        mcp_client = MCPClient(SERVER_PATH)
        await mcp_client.__aenter__()
        
        # MCP íˆ´ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        tool_list = await mcp_client.list_tools()
        openai_tools = [_mcp_schema_to_openai_tool(t) for t in tool_list]
        openai_tools = _sanitize(openai_tools)
        
        print(f"ğŸ”Œ MCP server connected: {SERVER_PATH}")
        print(f"ğŸ› ï¸  Available tools: {[t['function']['name'] for t in openai_tools]}")
        
    except Exception as e:
        print(f"âŒ Failed to initialize MCP client: {e}")
        raise


@app.on_event("shutdown")
async def shutdown_event():
    """ì„œë²„ ì¢…ë£Œ ì‹œ MCP í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬"""
    global mcp_client
    if mcp_client:
        try:
            await mcp_client.__aexit__(None, None, None)
        except Exception as e:
            print(f"Warning during MCP client cleanup: {e}")


# ---------- API ì—”ë“œí¬ì¸íŠ¸ë“¤ ----------
@app.get("/")
async def root():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {"message": "AI Agent Web Server is running", "status": "ok"}


@app.post("/api/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest, req: Request):
    """í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì±„íŒ… ìš”ì²­ì„ ë°›ëŠ” ì—”ë“œí¬ì¸íŠ¸"""
    try:
        # HTTP í—¤ë”ì—ì„œ ì¿ í‚¤ ì¶”ì¶œ (ìš°ì„ ìˆœìœ„: í—¤ë” > ìš”ì²­ ë³¸ë¬¸)
        cookies_from_header = req.headers.get("cookie", "")
        final_cookies = cookies_from_header or request.cookies or ""
        
        print(f"ğŸª Cookies from header: {cookies_from_header}")
        
        response = await process_chat_with_ai(
            request.message, 
            request.user_id, 
            final_cookies
        )
        return ChatResponse(response=response)
    except Exception as e:
        print(f"Error in chat endpoint: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "status": "healthy",
        "mcp_connected": mcp_client is not None,
        "tools_count": len(openai_tools)
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8081, reload=True)
