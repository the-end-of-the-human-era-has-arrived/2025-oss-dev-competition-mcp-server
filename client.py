import asyncio
import json
import os
from typing import Any, Dict, List

from fastmcp import Client as MCPClient
from openai import OpenAI
from dotenv import load_dotenv


# ---------- ìœ í‹¸: Pydantic ë³€í™˜ + ì„œëŸ¬ê²Œì´íŠ¸ ì œê±° ----------
def _to_dict(x: Any):
    """Pydantic(BaseModel) -> dict, ê·¸ ì™¸ëŠ” ê·¸ëŒ€ë¡œ"""
    if hasattr(x, "model_dump"):
        return x.model_dump()
    if hasattr(x, "dict"):
        return x.dict()
    return x

# U+D800..U+DFFF ì œê±°ìš© ë§¤í•‘ (ìœ íš¨í•˜ì§€ ì•Šì€ ì„œëŸ¬ê²Œì´íŠ¸ ë²”ìœ„)
_SURR_MAP = {i: None for i in range(0xD800, 0xE000)}

def _strip_surrogates(s: str) -> str:
    """ë¬¸ìì—´ì—ì„œ ì„œëŸ¬ê²Œì´íŠ¸ ì½”ë“œí¬ì¸íŠ¸ ì œê±°"""
    return s.translate(_SURR_MAP)

def _sanitize(obj: Any):
    """ë¬¸ìì—´/ë¦¬ìŠ¤íŠ¸/ë”•ì…”ë„ˆë¦¬(ë˜ëŠ” Pydantic)ë¥¼ ì¬ê·€ì ìœ¼ë¡œ ì •ë¦¬"""
    if isinstance(obj, str):
        return _strip_surrogates(obj)
    if isinstance(obj, list):
        return [_sanitize(v) for v in obj]
    if isinstance(obj, dict):
        return {(_sanitize(k) if isinstance(k, str) else k): _sanitize(v) for k, v in obj.items()}
    if hasattr(obj, "model_dump"):
        return _sanitize(obj.model_dump())
    if hasattr(obj, "dict"):
        return _sanitize(obj.dict())
    return obj
# -----------------------------------------------------------


load_dotenv()

OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
SERVER_PATH = os.getenv("MCP_SERVER_PATH", "server.py")


def _mcp_schema_to_openai_tool(tool: Any) -> Dict[str, Any]:
    """
    FastMCPì˜ Tool(Pydantic) ë˜ëŠ” dictë¥¼ OpenAI tools ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜.
    """
    t = _to_dict(tool)  # Pydantic -> dict
    name = t.get("name") or t.get("tool") or "tool"
    description = t.get("description", "")
    schema = t.get("inputSchema") or t.get("input_schema") or {"type": "object", "properties": {}}

    return {
        "type": "function",
        "function": {
            "name": _strip_surrogates(name),
            "description": _strip_surrogates(description),
            "parameters": _sanitize(schema),
        },
    }


def _to_str(res: Any) -> str:
    """íˆ´ ì‹¤í–‰ ê²°ê³¼ë¥¼ OpenAI tool ë©”ì‹œì§€ contentë¡œ ì•ˆì „ ë³€í™˜"""
    if isinstance(res, str):
        return _strip_surrogates(res)
    if hasattr(res, "text") and isinstance(res.text, str):
        return _strip_surrogates(res.text)
    d = _to_dict(res)
    try:
        return _strip_surrogates(json.dumps(_sanitize(d), ensure_ascii=False))
    except Exception:
        return _strip_surrogates(str(d))


async def chat_loop() -> None:
    # MCP ì„œë²„(stdio) ì—°ê²°/ìŠ¤í°
    async with MCPClient(SERVER_PATH) as mcp:
        client = OpenAI()

        # MCP íˆ´ íƒìƒ‰ -> OpenAI tool ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜
        tool_list = await mcp.list_tools()
        openai_tools = [_mcp_schema_to_openai_tool(t) for t in tool_list]
        openai_tools = _sanitize(openai_tools)

        print(f"ğŸ”Œ Connected to MCP server at {SERVER_PATH}")
        print("ğŸ› ï¸  Tools available to the model: " + ", ".join([t['function']['name'] for t in openai_tools]))
        print("ğŸ’¬ í•œêµ­ì–´/ì˜ì–´ë¡œ ì§ˆë¬¸í•˜ì„¸ìš”. ì¢…ë£Œ: /exit ë˜ëŠ” /quit\n")

        messages: List[Dict[str, Any]] = [
            {
                "role": "system",
                "content": (
                    "You are a helpful assistant. You have access to several tools via MCP. "
                    "Prefer using tools when the user asks about Notion content or actions. "
                    "ì§€ì› ì–¸ì–´: í•œêµ­ì–´ì™€ ì˜ì–´."
                ),
            }
        ]

        while True:
            user_in = input("You: ").strip()
            if not user_in:
                continue
            if user_in.lower() in ("/exit", "/quit"):
                print("Bye!")
                return

            # ì‚¬ìš©ì ì…ë ¥ë„ sanitize
            messages.append({"role": "user", "content": _strip_surrogates(user_in)})

            # Tool-call ë£¨í”„
            while True:
                resp = client.chat.completions.create(
                    model=OPENAI_MODEL,
                    messages=_sanitize(messages),   # ë©”ì‹œì§€ payloadë¥¼ í•­ìƒ sanitize
                    tools=openai_tools,
                )
                choice = resp.choices[0]
                msg = choice.message

                if msg.tool_calls:
                    # íˆ´ í˜¸ì¶œ ì²˜ë¦¬
                    for tc in msg.tool_calls:
                        tname = tc.function.name
                        targs = tc.function.arguments or "{}"
                        try:
                            parsed = json.loads(targs)
                        except json.JSONDecodeError:
                            parsed = {}

                        # MCP íˆ´ ì‹¤í–‰
                        result = await mcp.call_tool(tname, parsed)

                        # ëª¨ë¸ì˜ íˆ´ í˜¸ì¶œ ë©”ì‹œì§€
                        messages.append(
                            {
                                "role": "assistant",
                                "tool_calls": [
                                    {
                                        "id": tc.id,
                                        "type": "function",
                                        "function": {"name": tname, "arguments": json.dumps(parsed, ensure_ascii=False)},
                                    }
                                ],
                            }
                        )
                        # íˆ´ ê²°ê³¼ ë©”ì‹œì§€
                        messages.append(
                            {
                                "role": "tool",
                                "tool_call_id": tc.id,
                                "name": tname,
                                "content": _to_str(result),
                            }
                        )
                    # íˆ´ ì¶œë ¥ê¹Œì§€ ëŒ€í™”ì— ë°˜ì˜í–ˆìœ¼ë‹ˆ, í•œ ë²ˆ ë” ìš”ì²­í•´ ìµœì¢… ë‹µë³€ ë°›ê¸°
                    continue

                # ë” ì´ìƒ íˆ´ í˜¸ì¶œì´ ì—†ìœ¼ë©´ ìµœì¢… ë‹µë³€
                final_text = msg.content or ""
                print(f"Assistant: {final_text}\n")
                messages.append({"role": "assistant", "content": _strip_surrogates(final_text)})
                break


if __name__ == "__main__":
    try:
        asyncio.run(chat_loop())
    except KeyboardInterrupt:
        pass
